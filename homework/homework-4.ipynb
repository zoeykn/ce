{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### ðŸŽ“ **Professor**: Apostolos Filippas\n",
    "\n",
    "### ðŸ“˜ **Class**: AI Engineering\n",
    "\n",
    "### ðŸ“‹ **Homework 4**: Embeddings & Semantic Search\n",
    "\n",
    "### ðŸ“… **Due Date**: Day of Lecture 5, 11:59 PM\n",
    "\n",
    "\n",
    "**Note**: You are not allowed to share the contents of this notebook with anyone outside this class without written permission by the professor.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this homework, you'll build on Homework 3 (BM25 search) by adding **embedding-based semantic search**.\n",
    "\n",
    "You will:\n",
    "1. **Generate embeddings** using both local (Hugging Face) and API (OpenAI) models\n",
    "2. **Implement cosine similarity** from scratch\n",
    "3. **Implement semantic search** from scratch\n",
    "4. **Compare BM25 vs semantic search** using Recall\n",
    "5. **Compare different embedding models** and analyze their differences\n",
    "\n",
    "**Total Points: 95**\n",
    "\n",
    "---\n",
    "\n",
    "## Instructions\n",
    "\n",
    "- Complete all tasks by filling in code where you see `# YOUR CODE HERE`\n",
    "- You may use ChatGPT, Claude, documentation, Stack Overflow, etc.\n",
    "- When using external resources, briefly cite them in a comment\n",
    "- Run all cells before submitting to ensure they work\n",
    "\n",
    "**Submission:**\n",
    "1. Create a branch called `homework-4`\n",
    "2. Commit and push your work\n",
    "3. Create a PR and merge to main\n",
    "4. Submit the `.ipynb` file on Blackboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Task 1: Environment Setup (10 points)\n",
    "\n",
    "### 1a. Imports (5 pts)\n",
    "\n",
    "Import the required libraries and load the WANDS data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ruff: noqa: E402\n",
    "\n",
    "# Standard imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Import ONLY data loading from helpers\n",
    "import sys\n",
    "sys.path.append('../scripts')\n",
    "from helpers import load_wands_products, load_wands_queries, load_wands_labels\n",
    "\n",
    "# Embedding libraries - we use these directly\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import litellm\n",
    "\n",
    "# Load environment variables for API keys\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "pd.set_option('display.max_colwidth', 80)\n",
    "print(\"All imports successful!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the WANDS dataset\n",
    "products = load_wands_products()\n",
    "queries = load_wands_queries()\n",
    "labels = load_wands_labels()\n",
    "\n",
    "print(f\"Products: {len(products):,}\")\n",
    "print(f\"Queries: {len(queries):,}\")\n",
    "print(f\"Labels: {len(labels):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1b. Copy BM25 functions from HW3 (5 pts)\n",
    "\n",
    "Copy your BM25 implementation from Homework 3. We'll use it to compare against semantic search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy your BM25 functions from Homework 3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Task 2: Understanding Embeddings (15 points)\n",
    "\n",
    "### 2a. Load a local model and generate embeddings (5 pts)\n",
    "\n",
    "Use `sentence-transformers` to load a local embedding model and generate embeddings for a list of words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the all-MiniLM-L6-v2 model using SentenceTransformer\n",
    "# Then generate embeddings for each word in the list\n",
    "words = [\"wooden coffee table\", \"oak dining table\", \"red leather sofa\", \"blue area rug\", \"kitchen sink\"]\n",
    "\n",
    "# YOUR CODE HERE\n",
    "\n",
    "# Print the number of embeddings you generated and the dimension of the embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2b. Implement cosine similarity and create a similarity matrix (5 pts)\n",
    "\n",
    "Implement cosine similarity from scratch:\n",
    "\n",
    "$$\\text{cosine\\_similarity}(a, b) = \\frac{a \\cdot b}{\\|a\\| \\times \\|b\\|}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement cosine similarity from scratch\n",
    "\n",
    "# Create similarity matrix\n",
    "\n",
    "# Display as DataFrame\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2c. Embed using OpenAI API (5 pts)\n",
    "\n",
    "Use `litellm` to get embeddings from OpenAI's API and compare dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use litellm to get an embedding from OpenAI's text-embedding-3-small model\n",
    "# Compare the dimension with the local model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Task 3: Batch Embedding Products (20 points)\n",
    "\n",
    "### 3a. Embed a product sample (10 pts)\n",
    "\n",
    "Create a combined text field and embed 5,000 products using the local model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a consistent sample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a combined text field (product_name + product_class)\n",
    "# Then embed all products using model.encode()\n",
    "\n",
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3b. Save and load embeddings (5 pts)\n",
    "\n",
    "Save embeddings to a `.npy` file so you don't have to recompute them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save embeddings to ../temp/hw4_embeddings.npy\n",
    "# Save products_sample to ../temp/hw4_products.csv\n",
    "# Then load them back and verify they match"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3c. Cost estimation (5 pts)\n",
    "\n",
    "Estimate the cost to embed all 43K products using OpenAI's API.\n",
    "\n",
    "**Pricing**: text-embedding-3-small costs ~$0.02 per 1 million tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use tiktoken to count actual tokens in the sample\n",
    "# Then extrapolate to estimate cost for the full dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Task 4: Semantic Search (25 points)\n",
    "\n",
    "### 4a. Implement semantic search (15 pts)\n",
    "\n",
    "Implement a semantic search function from scratch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement batch cosine similarity for efficiency\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement semantic search\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test semantic search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4b. Evaluate and compare BM25 vs semantic search (10 pts)\n",
    "\n",
    "Implement Recall@k and compare the two search methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement Recall@k\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build BM25 index for comparison\n",
    "\n",
    "# Filter queries to those with products in our sample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate both BM25 and semantic search on all queries\n",
    "# Calculate Recall@10 for each method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize comparison\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Task 5: Compare Embedding Models (20 points)\n",
    "\n",
    "### 5a. Embed products with two different models (10 pts)\n",
    "\n",
    "Compare embeddings from:\n",
    "- `BAAI/bge-base-en-v1.5`\n",
    "- `sentence-transformers/all-mpnet-base-v2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the two embedding models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embed products with both models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5b. Compare search results between models (10 pts)\n",
    "\n",
    "Evaluate both models on the same queries and analyze differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare results for specific queries\n",
    "test_queries = [\"comfortable sofa\", \"star wars rug\", \"modern coffee table\"]\n",
    "# add more!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize model comparison with a scatter plot\n",
    "# X-axis: BGE Recall@10, Y-axis: MPNet Recall@10\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Task 6: Git Submission (5 points)\n",
    "\n",
    "Submit your work using the Git workflow:\n",
    "\n",
    "- [ ] Create a new branch called `homework-4`\n",
    "- [ ] Commit your work with a meaningful message\n",
    "- [ ] Push to GitHub\n",
    "- [ ] Create a Pull Request\n",
    "- [ ] Merge the PR to main\n",
    "- [ ] Submit the `.ipynb` file on Blackboard\n",
    "\n",
    "The TA will verify your submission by checking the merged PR on GitHub."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ce)",
   "language": "python",
   "name": "ce"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
